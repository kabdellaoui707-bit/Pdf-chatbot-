import streamlit as st
import fitz  # PyMuPDF
from sentence_transformers import SentenceTransformer, util

@st.cache_resource
def load_model():
    return SentenceTransformer("all-MiniLM-L6-v2")

model = load_model()

def extract_pdf_chunks(pdf_file, max_len=500):
    doc = fitz.open(stream=pdf_file.read(), filetype="pdf")
    chunks = []
    for page_num, page in enumerate(doc, start=1):
        text = page.get_text()
        paragraphs = [p.strip() for p in text.split("\n\n") if len(p.strip()) > 100]
        for para in paragraphs:
            chunks.append((page_num, para[:max_len]))
    return chunks

st.set_page_config(page_title="ğŸ“˜ PDF Chatbot", layout="centered")
st.markdown("## ğŸ¤– Ø¨ÙˆØª Ø°ÙƒØ§Ø¡ ÙŠÙ‚Ø±Ø£ PDF ÙˆÙŠØ¬ÙŠØ¨ Ø¹Ù„Ù‰ Ø£Ø³Ø¦Ù„ØªÙƒ")

uploaded_file = st.file_uploader("ğŸ“ Ø§Ø±ÙØ¹ Ù…Ù„Ù PDF", type=["pdf"])

if uploaded_file:
    with st.spinner("ğŸ“– Ø¬Ø§Ø±Ù Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù..."):
        pdf_chunks = extract_pdf_chunks(uploaded_file)
        paragraphs_text = [chunk[1] for chunk in pdf_chunks]
        embeddings = model.encode(paragraphs_text, convert_to_tensor=True)

    question = st.text_input("ğŸ“ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹ Ø¹Ù† Ù…Ø­ØªÙˆÙ‰ PDF:")

    if question:
        with st.spinner("ğŸ¤” ÙŠÙÙÙƒÙ‘Ø±..."):
            question_embedding = model.encode(question, convert_to_tensor=True)
            hits = util.semantic_search(question_embedding, embeddings, top_k=1)[0]
            hit = hits[0]
            idx = hit["corpus_id"]
            score = hit["score"]
            page, para = pdf_chunks[idx]
            st.markdown(f"ğŸ“„ Ù…Ù† Ø§Ù„ØµÙØ­Ø© {page} (Ø¯Ø±Ø¬Ø© Ø§Ù„ØªØ·Ø§Ø¨Ù‚: {score:.2f})")
            st.info(para)
